{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'lsb_release' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "get_ipython().system('lsb_release -a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"cell_imagesMalaria\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'sudo' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "get_ipython().system('sudo apt install tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Dataset Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Too many parameters - --filelimit\n"
     ]
    }
   ],
   "source": [
    "get_ipython().system('tree --dirsfirst --filelimit 5 \"./cell_imagesMalaria\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "base_dir = os.path.join('./cell_imagesMalaria')\n",
    "infected_dir = os.path.join(base_dir,'Parasitized')\n",
    "healthy_dir = os.path.join(base_dir,'Uninfected')\n",
    "\n",
    "infected_files = glob.glob(infected_dir+'/*.png')\n",
    "healthy_files = glob.glob(healthy_dir+'/*.png')\n",
    "len(infected_files), len(healthy_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_df = pd.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function pandas.core.generic.NDFrame.head(self, n=5)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "files_df = pd.DataFrame({\n",
    "    'filename': infected_files + healthy_files,\n",
    "    'label': ['malaria'] * len(infected_files) + ['healthy'] * len(healthy_files)\n",
    "}).sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "          filename\t                                    label\n",
    "0\t./cell_images/Parasitized/C59P20thinF_IMG_2015...\tmalaria\n",
    "1\t./cell_images/Parasitized/C180P141NThinF_IMG_2...\tmalaria\n",
    "2\t./cell_images/Uninfected/C154P115ThinF_IMG_201...\thealthy\n",
    "3\t./cell_images/Uninfected/C69P30N_ThinF_IMG_201...\thealthy\n",
    "4\t./cell_images/Uninfected/C182P143NThinF_IMG_20...\thealthy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Train, Validation and Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "train_files, test_files, train_labels, test_labels = train_test_split(files_df['filename'].values,\n",
    "                                                                      files_df['label'].values, \n",
    "                                                                      test_size=0.3, random_state=42)\n",
    "train_files, val_files, train_labels, val_labels = train_test_split(train_files,\n",
    "                                                                    train_labels, \n",
    "                                                                    test_size=0.1, random_state=42)\n",
    "\n",
    "print(train_files.shape, val_files.shape, test_files.shape)\n",
    "print('Train:', Counter(train_labels), '\\nVal:', Counter(val_labels), '\\nTest:', Counter(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Image Dimension Summary Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from concurrent import futures\n",
    "import threading\n",
    "\n",
    "def get_img_shape_parallel(idx, img, total_imgs):\n",
    "    if idx % 5000 == 0 or idx == (total_imgs - 1):\n",
    "        print('{}: working on img num: {}'.format(threading.current_thread().name,\n",
    "                                                  idx))\n",
    "    return cv2.imread(img).shape\n",
    "  \n",
    "ex = futures.ThreadPoolExecutor(max_workers=None)\n",
    "data_inp = [(idx, img, len(train_files)) for idx, img in enumerate(train_files)]\n",
    "print('Starting Img shape computation:')\n",
    "train_img_dims_map = ex.map(get_img_shape_parallel, \n",
    "                            [record[0] for record in data_inp],\n",
    "                            [record[1] for record in data_inp],\n",
    "                            [record[2] for record in data_inp])\n",
    "train_img_dims = list(train_img_dims_map)\n",
    "print('Min Dimensions:', np.min(train_img_dims, axis=0)) \n",
    "print('Avg Dimensions:', np.mean(train_img_dims, axis=0))\n",
    "print('Median Dimensions:', np.median(train_img_dims, axis=0))\n",
    "print('Max Dimensions:', np.max(train_img_dims, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting Img shape computation:\n",
    "ThreadPoolExecutor-0_0: working on img num: 0\n",
    "ThreadPoolExecutor-0_17: working on img num: 5000\n",
    "ThreadPoolExecutor-0_15: working on img num: 10000\n",
    "ThreadPoolExecutor-0_1: working on img num: 15000\n",
    "ThreadPoolExecutor-0_7: working on img num: 17360\n",
    "Min Dimensions: [46 46  3]\n",
    "Avg Dimensions: [132.77311215 132.45757733   3.        ]\n",
    "Median Dimensions: [130. 130.   3.]\n",
    "Max Dimensions: [385 394   3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Resizing the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIMS = (125, 125)\n",
    "\n",
    "def get_img_data_parallel(idx, img, total_imgs):\n",
    "    if idx % 5000 == 0 or idx == (total_imgs - 1):\n",
    "        print('{}: working on img num: {}'.format(threading.current_thread().name,\n",
    "                                                  idx))\n",
    "    img = cv2.imread(img)\n",
    "    img = cv2.resize(img, dsize=IMG_DIMS, \n",
    "                     interpolation=cv2.INTER_CUBIC)\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "    return img\n",
    "\n",
    "ex = futures.ThreadPoolExecutor(max_workers=None)\n",
    "train_data_inp = [(idx, img, len(train_files)) for idx, img in enumerate(train_files)]\n",
    "val_data_inp = [(idx, img, len(val_files)) for idx, img in enumerate(val_files)]\n",
    "test_data_inp = [(idx, img, len(test_files)) for idx, img in enumerate(test_files)]\n",
    "\n",
    "print('Loading Train Images:')\n",
    "train_data_map = ex.map(get_img_data_parallel, \n",
    "                        [record[0] for record in train_data_inp],\n",
    "                        [record[1] for record in train_data_inp],\n",
    "                        [record[2] for record in train_data_inp])\n",
    "train_data = np.array(list(train_data_map))\n",
    "\n",
    "print('\\nLoading Validation Images:')\n",
    "val_data_map = ex.map(get_img_data_parallel, \n",
    "                        [record[0] for record in val_data_inp],\n",
    "                        [record[1] for record in val_data_inp],\n",
    "                        [record[2] for record in val_data_inp])\n",
    "val_data = np.array(list(val_data_map))\n",
    "\n",
    "print('\\nLoading Test Images:')\n",
    "test_data_map = ex.map(get_img_data_parallel, \n",
    "                        [record[0] for record in test_data_inp],\n",
    "                        [record[1] for record in test_data_inp],\n",
    "                        [record[2] for record in test_data_inp])\n",
    "test_data = np.array(list(test_data_map))\n",
    "\n",
    "train_data.shape, val_data.shape, test_data.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Train Images:\n",
    "ThreadPoolExecutor-1_0: working on img num: 0\n",
    "ThreadPoolExecutor-1_12: working on img num: 5000\n",
    "ThreadPoolExecutor-1_6: working on img num: 10000\n",
    "ThreadPoolExecutor-1_10: working on img num: 15000\n",
    "ThreadPoolExecutor-1_3: working on img num: 17360\n",
    "\n",
    "Loading Validation Images:\n",
    "ThreadPoolExecutor-1_13: working on img num: 0\n",
    "ThreadPoolExecutor-1_18: working on img num: 1928\n",
    "\n",
    "Loading Test Images:\n",
    "ThreadPoolExecutor-1_5: working on img num: 0\n",
    "ThreadPoolExecutor-1_19: working on img num: 5000\n",
    "ThreadPoolExecutor-1_8: working on img num: 8267\n",
    "\n",
    "((17361, 125, 125, 3), (1929, 125, 125, 3), (8268, 125, 125, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing the Sample Cell Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(1 , figsize = (8 , 8))\n",
    "n = 0 \n",
    "for i in range(16):\n",
    "    n += 1 \n",
    "    r = np.random.randint(0 , train_data.shape[0] , 1)\n",
    "    plt.subplot(4 , 4 , n)\n",
    "    plt.subplots_adjust(hspace = 0.5 , wspace = 0.5)\n",
    "    plt.imshow(train_data[r[0]]/255.)\n",
    "    plt.title('{}'.format(train_labels[r[0]]))\n",
    "    plt.xticks([]) , plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setingup config settings, Scale Images & Label encode classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "NUM_CLASSES = 2\n",
    "EPOCHS = 25\n",
    "INPUT_SHAPE = (125, 125, 3)\n",
    "\n",
    "train_imgs_scaled = train_data / 255.\n",
    "val_imgs_scaled = val_data / 255.\n",
    "\n",
    "# encode text category labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "train_labels_enc = le.transform(train_labels)\n",
    "val_labels_enc = le.transform(val_labels)\n",
    "\n",
    "print(train_labels[:6], train_labels_enc[:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ 'malaria'   'malaria'   'malaria'   'healthy'   'healthy'   'malaria' ]  [ 1  1  1  0  0  1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the TensorBoard notebook extension (optional)\n",
    "%load_ext tensorboard.notebook\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'2.0.0-alpha0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Building CNN from Scratch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = tf.keras.layers.Input(shape=INPUT_SHAPE)\n",
    "\n",
    "conv1 = tf.keras.layers.Conv2D(32, kernel_size=(3, 3), \n",
    "                               activation='relu', padding='same')(inp)\n",
    "pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "conv2 = tf.keras.layers.Conv2D(64, kernel_size=(3, 3), \n",
    "                               activation='relu', padding='same')(pool1)\n",
    "pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "conv3 = tf.keras.layers.Conv2D(128, kernel_size=(3, 3), \n",
    "                               activation='relu', padding='same')(pool2)\n",
    "pool3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "flat = tf.keras.layers.Flatten()(pool3)\n",
    "\n",
    "hidden1 = tf.keras.layers.Dense(512, activation='relu')(flat)\n",
    "drop1 = tf.keras.layers.Dropout(rate=0.3)(hidden1)\n",
    "hidden2 = tf.keras.layers.Dense(512, activation='relu')(drop1)\n",
    "drop2 = tf.keras.layers.Dropout(rate=0.3)(hidden2)\n",
    "\n",
    "out = tf.keras.layers.Dense(1, activation='sigmoid')(drop2)\n",
    "\n",
    "model = tf.keras.Model(inputs=inp, outputs=out)\n",
    "model.compile(optimizer='adam',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: \"model\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "\n",
    "input_1 (InputLayer)         [(None, 125, 125, 3)]     0         \n",
    "_________________________________________________________________\n",
    "conv2d (Conv2D)              (None, 125, 125, 32)      896       \n",
    "_________________________________________________________________\n",
    "max_pooling2d (MaxPooling2D) (None, 62, 62, 32)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_1 (Conv2D)            (None, 62, 62, 64)        18496     \n",
    "_________________________________________________________________\n",
    "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 64)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_2 (Conv2D)            (None, 31, 31, 128)       73856     \n",
    "_________________________________________________________________\n",
    "max_pooling2d_2 (MaxPooling2 (None, 15, 15, 128)       0         \n",
    "_________________________________________________________________\n",
    "flatten (Flatten)            (None, 28800)             0         \n",
    "_________________________________________________________________\n",
    "dense (Dense)                (None, 512)               14746112  \n",
    "_________________________________________________________________\n",
    "dropout (Dropout)            (None, 512)               0         \n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 512)               262656    \n",
    "_________________________________________________________________\n",
    "dropout_1 (Dropout)          (None, 512)               0         \n",
    "_________________________________________________________________\n",
    "dense_2 (Dense)              (None, 1)                 513       \n",
    "\n",
    "Total params: 15,102,529\n",
    "                 \n",
    "Trainable params: 15,102,529\n",
    "                 \n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "logdir = os.path.join('/home/dipanzan_sarkar/projects/tensorboard_logs', \n",
    "                      datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                              patience=2, min_lr=0.000001)\n",
    "\n",
    "#early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, \n",
    "#                                              mode='auto', baseline=None, restore_best_weights=False)\n",
    "callbacks = [reduce_lr, tensorboard_callback]\n",
    "\n",
    "history = model.fit(x=train_imgs_scaled, y=train_labels_enc, \n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS, \n",
    "                    validation_data=(val_imgs_scaled, val_labels_enc), \n",
    "                    callbacks=callbacks,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on 17361 samples, validate on 1929 samples\n",
    "\n",
    "Epoch 1/25\n",
    "\n",
    "17361/17361 [==============================] - 32s 2ms/sample - loss: 0.4373 - accuracy: 0.7814 - val_loss: 0.1834 - val_accuracy: 0.9393\n",
    "\n",
    "Epoch 2/25\n",
    "\n",
    "17361/17361 [==============================] - 30s 2ms/sample - loss: 0.1725 - accuracy: 0.9434 - val_loss: 0.1567 - val_accuracy: 0.9513\n",
    "\n",
    "Epoch 3/25\n",
    "\n",
    "17361/17361 [==============================] - 30s 2ms/sample - loss: 0.1418 - accuracy: 0.9543 - val_loss: 0.1459 - val_accuracy: 0.9570\n",
    "\n",
    "Epoch 4/25\n",
    "\n",
    "17361/17361 [==============================] - 30s 2ms/sample - loss: 0.1235 - accuracy: 0.9585 - val_loss: 0.1464 - val_accuracy: 0.9611\n",
    "\n",
    "Epoch 5/25\n",
    "\n",
    "17361/17361 [==============================] - 30s 2ms/sample - loss: 0.1115 - accuracy: 0.9619 - val_loss: 0.1444 - val_accuracy: 0.9596\n",
    "\n",
    "Epoch 6/25\n",
    "\n",
    "17361/17361 [==============================] - 30s 2ms/sample - loss: 0.0989 - accuracy: 0.9672 - val_loss: 0.1767 - val_accuracy: 0.9570\n",
    "\n",
    "Epoch 7/25\n",
    "\n",
    "17361/17361 [==============================] - 30s 2ms/sample - loss: 0.0859 - accuracy: 0.9689 - val_loss: 0.1617 - val_accuracy: 0.9554\n",
    "\n",
    "Epoch 8/25\n",
    "\n",
    "17361/17361 [==============================] - 30s 2ms/sample - loss: 0.0574 - accuracy: 0.9809 - val_loss: 0.1968 - val_accuracy: 0.9544\n",
    "\n",
    "Epoch 9/25\n",
    "\n",
    "17361/17361 [==============================] - 30s 2ms/sample - loss: 0.0432 - accuracy: 0.9851 - val_loss: 0.2329 - val_accuracy: 0.9559\n",
    "\n",
    "Epoch 10/25\n",
    "\n",
    "17361/17361 [==============================] - 30s 2ms/sample - loss: 0.0270 - accuracy: 0.9905 - val_loss: 0.2455 - val_accuracy: 0.9554\n",
    "\n",
    "Epoch 11/25\n",
    "\n",
    "17361/17361 [==============================] - 30s 2ms/sample - loss: 0.0184 - accuracy: 0.9946 - val_loss: 0.2751 - val_accuracy: 0.9539\n",
    "\n",
    "Epoch 12/25\n",
    "\n",
    "17361/17361 [==============================] - 30s 2ms/sample - loss: 0.0123 - accuracy: 0.9965 - val_loss: 0.3028 - val_accuracy: 0.9570\n",
    "\n",
    "Epoch 13/25\n",
    "\n",
    "17361/17361 [==============================] - 30s 2ms/sample - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.3233 - val_accuracy: 0.9565\n",
    "\n",
    "Epoch 14/25\n",
    "\n",
    "17361/17361 [==============================] - 30s 2ms/sample - loss: 0.0070 - accuracy: 0.9981 - val_loss: 0.3282 - val_accuracy: 0.9533\n",
    "\n",
    "Epoch 15/25\n",
    "\n",
    "17361/17361 [==============================] - 30s 2ms/sample - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.3340 - val_accuracy: 0.9559\n",
    "\n",
    "Epoch 16/25\n",
    "\n",
    "17361/17361 [==============================] - 30s 2ms/sample - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.3428 - val_accuracy: 0.9570\n",
    "\n",
    "Epoch 17/25\n",
    "\n",
    "17361/17361 [==============================] - 30s 2ms/sample - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.3518 - val_accuracy: 0.9570\n",
    "\n",
    "Epoch 18/25\n",
    "\n",
    "17361/17361 [==============================] - 30s 2ms/sample - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.3586 - val_accuracy: 0.9570\n",
    "\n",
    "Epoch 19/25\n",
    "\n",
    "17361/17361 [==============================] - 30s 2ms/sample - loss: 0.0037 - accuracy: 0.9993 - val_loss: 0.3597 - val_accuracy: 0.9570\n",
    "\n",
    "Epoch 20/25\n",
    "\n",
    "17361/17361 [==============================] - 30s 2ms/sample - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.3596 - val_accuracy: 0.9570\n",
    "\n",
    "Epoch 21/25\n",
    "\n",
    "17361/17361 [==============================] - 30s 2ms/sample - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.3638 - val_accuracy: 0.9570\n",
    "\n",
    "Epoch 22/25\n",
    "\n",
    "17361/17361 [==============================] - 30s 2ms/sample - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.3669 - val_accuracy: 0.9565\n",
    "\n",
    "Epoch 23/25\n",
    "\n",
    "17361/17361 [==============================] - 30s 2ms/sample - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.3681 - val_accuracy: 0.9565\n",
    "\n",
    "Epoch 24/25\n",
    "\n",
    "17361/17361 [==============================] - 30s 2ms/sample - loss: 0.0036 - accuracy: 0.9993 - val_loss: 0.3693 - val_accuracy: 0.9565\n",
    "\n",
    "Epoch 25/25\n",
    "\n",
    "17361/17361 [==============================] - 30s 2ms/sample - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.3699 - val_accuracy: 0.9559"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "t = f.suptitle('Basic CNN Performance', fontsize=12)\n",
    "f.subplots_adjust(top=0.85, wspace=0.3)\n",
    "\n",
    "max_epoch = len(history.history['accuracy'])+1\n",
    "epoch_list = list(range(1,max_epoch))\n",
    "ax1.plot(epoch_list, history.history['accuracy'], label='Train Accuracy')\n",
    "ax1.plot(epoch_list, history.history['val_accuracy'], label='Validation Accuracy')\n",
    "ax1.set_xticks(np.arange(1, max_epoch, 5))\n",
    "ax1.set_ylabel('Accuracy Value')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_title('Accuracy')\n",
    "l1 = ax1.legend(loc=\"best\")\n",
    "\n",
    "ax2.plot(epoch_list, history.history['loss'], label='Train Loss')\n",
    "ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\n",
    "ax2.set_xticks(np.arange(1, max_epoch, 5))\n",
    "ax2.set_ylabel('Loss Value')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_title('Loss')\n",
    "l2 = ax2.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: Frozen the Pre-trained CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = tf.keras.applications.vgg19.VGG19(include_top=False, weights='imagenet', \n",
    "                                        input_shape=INPUT_SHAPE)\n",
    "vgg.trainable = False\n",
    "# Freeze the layers\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "base_vgg = vgg\n",
    "base_out = base_vgg.output\n",
    "pool_out = tf.keras.layers.Flatten()(base_out)\n",
    "hidden1 = tf.keras.layers.Dense(512, activation='relu')(pool_out)\n",
    "drop1 = tf.keras.layers.Dropout(rate=0.3)(hidden1)\n",
    "hidden2 = tf.keras.layers.Dense(512, activation='relu')(drop1)\n",
    "drop2 = tf.keras.layers.Dropout(rate=0.3)(hidden2)\n",
    "\n",
    "out = tf.keras.layers.Dense(1, activation='sigmoid')(drop2)\n",
    "\n",
    "model = tf.keras.Model(inputs=base_vgg.input, outputs=out)\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-4),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: \"model_1\"\n",
    "    \n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "_________________________________________________________________\n",
    "input_2 (InputLayer)         [(None, 125, 125, 3)]     0         \n",
    "_________________________________________________________________\n",
    "block1_conv1 (Conv2D)        (None, 125, 125, 64)      1792      \n",
    "_________________________________________________________________\n",
    "block1_conv2 (Conv2D)        (None, 125, 125, 64)      36928     \n",
    "_________________________________________________________________\n",
    "block1_pool (MaxPooling2D)   (None, 62, 62, 64)        0         \n",
    "_________________________________________________________________\n",
    "block2_conv1 (Conv2D)        (None, 62, 62, 128)       73856     \n",
    "_________________________________________________________________\n",
    "block2_conv2 (Conv2D)        (None, 62, 62, 128)       147584    \n",
    "_________________________________________________________________\n",
    "block2_pool (MaxPooling2D)   (None, 31, 31, 128)       0         \n",
    "_________________________________________________________________\n",
    "block3_conv1 (Conv2D)        (None, 31, 31, 256)       295168    \n",
    "_________________________________________________________________\n",
    "block3_conv2 (Conv2D)        (None, 31, 31, 256)       590080    \n",
    "_________________________________________________________________\n",
    "block3_conv3 (Conv2D)        (None, 31, 31, 256)       590080    \n",
    "_________________________________________________________________\n",
    "block3_conv4 (Conv2D)        (None, 31, 31, 256)       590080    \n",
    "_________________________________________________________________\n",
    "block3_pool (MaxPooling2D)   (None, 15, 15, 256)       0         \n",
    "_________________________________________________________________\n",
    "block4_conv1 (Conv2D)        (None, 15, 15, 512)       1180160   \n",
    "_________________________________________________________________\n",
    "block4_conv2 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block4_conv3 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block4_conv4 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block4_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
    "_________________________________________________________________\n",
    "block5_conv1 (Conv2D)        (None, 7, 7, 512)         2359808   \n",
    "_________________________________________________________________\n",
    "block5_conv2 (Conv2D)        (None, 7, 7, 512)         2359808   \n",
    "_________________________________________________________________\n",
    "block5_conv3 (Conv2D)        (None, 7, 7, 512)         2359808   \n",
    "_________________________________________________________________\n",
    "block5_conv4 (Conv2D)        (None, 7, 7, 512)         2359808   \n",
    "_________________________________________________________________\n",
    "block5_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
    "_________________________________________________________________\n",
    "flatten_1 (Flatten)          (None, 4608)              0         \n",
    "_________________________________________________________________\n",
    "dense_3 (Dense)              (None, 512)               2359808   \n",
    "_________________________________________________________________\n",
    "dropout_2 (Dropout)          (None, 512)               0         \n",
    "_________________________________________________________________\n",
    "dense_4 (Dense)              (None, 512)               262656    \n",
    "_________________________________________________________________\n",
    "dropout_3 (Dropout)          (None, 512)               0         \n",
    "_________________________________________________________________\n",
    "dense_5 (Dense)              (None, 1)                 513       \n",
    "\n",
    "_________________________________________________________________\n",
    "Total params: 22,647,361\n",
    "    \n",
    "Trainable params: 2,622,977\n",
    "\n",
    "Non-trainable params: 20,024,384\n",
    "_________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Layers:\", len(model.layers))\n",
    "print(\"Total trainable layers:\", sum([1 for l in model.layers if l.trainable]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total Layers: 28\n",
    "    \n",
    "Total trainable layers: 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                              patience=2, min_lr=0.000001)\n",
    "\n",
    "#early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=15, \n",
    "#                                              mode='auto', baseline=None, restore_best_weights=False)\n",
    "callbacks = [reduce_lr, tensorboard_callback]\n",
    "\n",
    "history = model.fit(x=train_imgs_scaled, y=train_labels_enc, \n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS, \n",
    "                    validation_data=(val_imgs_scaled, val_labels_enc), \n",
    "                    callbacks=callbacks,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on 17361 samples, validate on 1929 samples\n",
    "\n",
    "Epoch 1/25\n",
    "\n",
    "17361/17361 [==============================] - 92s 5ms/sample - loss: 0.3923 - accuracy: 0.8190 - val_loss: 0.2623 - val_accuracy: 0.8922\n",
    "                \n",
    "Epoch 2/25\n",
    "\n",
    "17361/17361 [==============================] - 87s 5ms/sample - loss: 0.2883 - accuracy: 0.8796 - val_loss: 0.2270 - val_accuracy: 0.9051\n",
    "\n",
    "Epoch 3/25\n",
    "\n",
    "17361/17361 [==============================] - 87s 5ms/sample - loss: 0.2601 - accuracy: 0.8957 - val_loss: 0.3761 - val_accuracy: 0.8383\n",
    "\n",
    "Epoch 4/25\n",
    "\n",
    "17361/17361 [==============================] - 87s 5ms/sample - loss: 0.2360 - accuracy: 0.9074 - val_loss: 0.1960 - val_accuracy: 0.9253\n",
    "\n",
    "Epoch 5/25\n",
    "\n",
    "17361/17361 [==============================] - 87s 5ms/sample - loss: 0.2210 - accuracy: 0.9138 - val_loss: 0.1939 - val_accuracy: 0.9269\n",
    "\n",
    "Epoch 6/25\n",
    "\n",
    "17361/17361 [==============================] - 87s 5ms/sample - loss: 0.2155 - accuracy: 0.9160 - val_loss: 0.2261 - val_accuracy: 0.9129\n",
    "\n",
    "Epoch 7/25\n",
    "\n",
    "17361/17361 [==============================] - 87s 5ms/sample - loss: 0.2053 - accuracy: 0.9210 - val_loss: 0.1834 - val_accuracy: 0.9305\n",
    "\n",
    "Epoch 8/25\n",
    "\n",
    "17361/17361 [==============================] - 87s 5ms/sample - loss: 0.1966 - accuracy: 0.9252 - val_loss: 0.1769 - val_accuracy: 0.9321\n",
    "\n",
    "Epoch 9/25\n",
    "\n",
    "17361/17361 [==============================] - 87s 5ms/sample - loss: 0.1929 - accuracy: 0.9265 - val_loss: 0.2780 - val_accuracy: 0.8875\n",
    "\n",
    "Epoch 10/25\n",
    "\n",
    "17361/17361 [==============================] - 87s 5ms/sample - loss: 0.1840 - accuracy: 0.9305 - val_loss: 0.1755 - val_accuracy: 0.9357\n",
    "\n",
    "Epoch 11/25\n",
    "\n",
    "17361/17361 [==============================] - 87s 5ms/sample - loss: 0.1792 - accuracy: 0.9311 - val_loss: 0.2105 - val_accuracy: 0.9181\n",
    "\n",
    "Epoch 12/25\n",
    "\n",
    "17361/17361 [==============================] - 87s 5ms/sample - loss: 0.1762 - accuracy: 0.9333 - val_loss: 0.2308 - val_accuracy: 0.9108\n",
    "\n",
    "Epoch 13/25\n",
    "\n",
    "17361/17361 [==============================] - 87s 5ms/sample - loss: 0.1482 - accuracy: 0.9472 - val_loss: 0.1837 - val_accuracy: 0.9352\n",
    "\n",
    "Epoch 14/25\n",
    "\n",
    "17361/17361 [==============================] - 87s 5ms/sample - loss: 0.1423 - accuracy: 0.9482 - val_loss: 0.1816 - val_accuracy: 0.9352\n",
    "\n",
    "Epoch 15/25\n",
    "\n",
    "17361/17361 [==============================] - 87s 5ms/sample - loss: 0.1295 - accuracy: 0.9533 - val_loss: 0.1796 - val_accuracy: 0.9305\n",
    "\n",
    "Epoch 16/25\n",
    "\n",
    "17361/17361 [==============================] - 87s 5ms/sample - loss: 0.1276 - accuracy: 0.9559 - val_loss: 0.1751 - val_accuracy: 0.9362\n",
    "\n",
    "Epoch 17/25\n",
    "\n",
    "17361/17361 [==============================] - 87s 5ms/sample - loss: 0.1235 - accuracy: 0.9568 - val_loss: 0.1734 - val_accuracy: 0.9393\n",
    "\n",
    "Epoch 18/25\n",
    "\n",
    "17361/17361 [==============================] - 87s 5ms/sample - loss: 0.1219 - accuracy: 0.9586 - val_loss: 0.1720 - val_accuracy: 0.9368\n",
    "\n",
    "Epoch 19/25\n",
    "\n",
    "17361/17361 [==============================] - 87s 5ms/sample - loss: 0.1204 - accuracy: 0.9589 - val_loss: 0.1705 - val_accuracy: 0.9357\n",
    "\n",
    "Epoch 20/25\n",
    "\n",
    "17361/17361 [==============================] - 87s 5ms/sample - loss: 0.1180 - accuracy: 0.9597 - val_loss: 0.1752 - val_accuracy: 0.9368\n",
    "\n",
    "Epoch 21/25\n",
    "\n",
    "17361/17361 [==============================] - 87s 5ms/sample - loss: 0.1134 - accuracy: 0.9603 - val_loss: 0.1960 - val_accuracy: 0.9274\n",
    "\n",
    "Epoch 22/25\n",
    "\n",
    "17361/17361 [==============================] - 87s 5ms/sample - loss: 0.1093 - accuracy: 0.9641 - val_loss: 0.1773 - val_accuracy: 0.9388\n",
    "\n",
    "Epoch 23/25\n",
    "\n",
    "17361/17361 [==============================] - 87s 5ms/sample - loss: 0.1062 - accuracy: 0.9649 - val_loss: 0.1720 - val_accuracy: 0.9388\n",
    "\n",
    "Epoch 24/25\n",
    "\n",
    "17361/17361 [==============================] - 87s 5ms/sample - loss: 0.1049 - accuracy: 0.9663 - val_loss: 0.1741 - val_accuracy: 0.9393\n",
    "\n",
    "Epoch 25/25\n",
    "\n",
    "17361/17361 [==============================] - 87s 5ms/sample - loss: 0.1017 - accuracy: 0.9666 - val_loss: 0.1751 - val_accuracy: 0.9430"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "t = f.suptitle('Basic CNN Performance', fontsize=12)\n",
    "f.subplots_adjust(top=0.85, wspace=0.3)\n",
    "\n",
    "max_epoch = len(history.history['accuracy'])+1\n",
    "epoch_list = list(range(1,max_epoch))\n",
    "ax1.plot(epoch_list, history.history['accuracy'], label='Train Accuracy')\n",
    "ax1.plot(epoch_list, history.history['val_accuracy'], label='Validation Accuracy')\n",
    "ax1.set_xticks(np.arange(1, max_epoch, 5))\n",
    "ax1.set_ylabel('Accuracy Value')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_title('Accuracy')\n",
    "l1 = ax1.legend(loc=\"best\")\n",
    "\n",
    "ax2.plot(epoch_list, history.history['loss'], label='Train Loss')\n",
    "ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\n",
    "ax2.set_xticks(np.arange(1, max_epoch, 5))\n",
    "ax2.set_ylabel('Loss Value')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_title('Loss')\n",
    "l2 = ax2.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Image Augmentors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
    "                                                                zoom_range=0.05, \n",
    "                                                                rotation_range=25,\n",
    "                                                                width_shift_range=0.05, \n",
    "                                                                height_shift_range=0.05, \n",
    "                                                                shear_range=0.05, horizontal_flip=True, \n",
    "                                                                fill_mode='nearest')\n",
    "\n",
    "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id = 0\n",
    "sample_generator = train_datagen.flow(train_data[img_id:img_id+1], train_labels[img_id:img_id+1],\n",
    "                                      batch_size=1)\n",
    "sample = [next(sample_generator) for i in range(0,5)]\n",
    "fig, ax = plt.subplots(1,5, figsize=(16, 6))\n",
    "print('Labels:', [item[1][0] for item in sample])\n",
    "l = [ax[i].imshow(sample[i][0][0]) for i in range(0,5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels: ['malaria', 'malaria', 'malaria', 'malaria', 'malaria']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow(train_data, train_labels_enc, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_generator = val_datagen.flow(val_data, val_labels_enc, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: Fine-tuneing Pre-trained CNN with Image Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = tf.keras.applications.vgg19.VGG19(include_top=False, weights='imagenet', \n",
    "                                        input_shape=INPUT_SHAPE)\n",
    "# Freeze the layers\n",
    "vgg.trainable = True\n",
    "\n",
    "set_trainable = False\n",
    "for layer in vgg.layers:\n",
    "    if layer.name in ['block5_conv1', 'block4_conv1']:\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "    \n",
    "base_vgg = vgg\n",
    "base_out = base_vgg.output\n",
    "pool_out = tf.keras.layers.Flatten()(base_out)\n",
    "hidden1 = tf.keras.layers.Dense(512, activation='relu')(pool_out)\n",
    "drop1 = tf.keras.layers.Dropout(rate=0.3)(hidden1)\n",
    "hidden2 = tf.keras.layers.Dense(512, activation='relu')(drop1)\n",
    "drop2 = tf.keras.layers.Dropout(rate=0.3)(hidden2)\n",
    "\n",
    "out = tf.keras.layers.Dense(1, activation='sigmoid')(drop2)\n",
    "\n",
    "model = tf.keras.Model(inputs=base_vgg.input, outputs=out)\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-5),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "print(\"Total Layers:\", len(model.layers))\n",
    "print(\"Total trainable layers:\", sum([1 for l in model.layers if l.trainable]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total   Layers :  28\n",
    "    \n",
    "Total   trainable   layers :  16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                              patience=2, min_lr=0.000001)\n",
    "\n",
    "#early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=15, \n",
    "#                                              mode='auto', baseline=None, restore_best_weights=False)\n",
    "callbacks = [reduce_lr, tensorboard_callback]\n",
    "train_steps_per_epoch = train_generator.n // train_generator.batch_size\n",
    "val_steps_per_epoch = val_generator.n // val_generator.batch_size\n",
    "history = model.fit_generator(train_generator, steps_per_epoch=train_steps_per_epoch, epochs=EPOCHS,\n",
    "                              validation_data=val_generator, validation_steps=val_steps_per_epoch, \n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 1/25\n",
    "\n",
    "271/271 [==============================] - 133s 489ms/step - loss: 0.2267 - accuracy: 0.9117 - val_loss: 0.1414 - val_accuracy: 0.9531\n",
    "\n",
    "Epoch 2/25\n",
    "\n",
    "271/271 [==============================] - 129s 475ms/step - loss: 0.1399 - accuracy: 0.9552 - val_loss: 0.1292 - val_accuracy: 0.9589\n",
    "\n",
    "Epoch 3/25\n",
    "\n",
    "271/271 [==============================] - 128s 474ms/step - loss: 0.1248 - accuracy: 0.9593 - val_loss: 0.1207 - val_accuracy: 0.9594\n",
    "\n",
    "Epoch 4/25\n",
    "\n",
    "\n",
    "271/271 [==============================] - 128s 474ms/step - loss: 0.1189 - accuracy: 0.9610 - val_loss: 0.1157 - val_accuracy: 0.9604\n",
    "\n",
    "Epoch 5/25\n",
    "\n",
    "271/271 [==============================] - 128s 474ms/step - loss: 0.1132 - accuracy: 0.9612 - val_loss: 0.1201 - val_accuracy: 0.9578\n",
    "\n",
    "Epoch 6/25\n",
    "\n",
    "271/271 [==============================] - 129s 475ms/step - loss: 0.1104 - accuracy: 0.9632 - val_loss: 0.1188 - val_accuracy: 0.9563\n",
    "\n",
    "Epoch 7/25\n",
    "\n",
    "271/271 [==============================] - 128s 473ms/step - loss: 0.1012 - accuracy: 0.9656 - val_loss: 0.1292 - val_accuracy: 0.9536\n",
    "\n",
    "Epoch 8/25\n",
    "\n",
    "271/271 [==============================] - 128s 474ms/step - loss: 0.1016 - accuracy: 0.9668 - val_loss: 0.1148 - val_accuracy: 0.9594\n",
    "\n",
    "Epoch 9/25\n",
    "\n",
    "271/271 [==============================] - 128s 474ms/step - loss: 0.0995 - accuracy: 0.9667 - val_loss: 0.1167 - val_accuracy: 0.9641\n",
    "\n",
    "Epoch 10/25\n",
    "\n",
    "271/271 [==============================] - 128s 474ms/step - loss: 0.0931 - accuracy: 0.9668 - val_loss: 0.1091 - val_accuracy: 0.9656\n",
    "\n",
    "Epoch 11/25\n",
    "\n",
    "271/271 [==============================] - 128s 474ms/step - loss: 0.0937 - accuracy: 0.9676 - val_loss: 0.1055 - val_accuracy: 0.9677\n",
    "\n",
    "Epoch 12/25\n",
    "\n",
    "271/271 [==============================] - 128s 473ms/step - loss: 0.0921 - accuracy: 0.9687 - val_loss: 0.1125 - val_accuracy: 0.9625\n",
    "\n",
    "Epoch 13/25\n",
    "\n",
    "271/271 [==============================] - 128s 474ms/step - loss: 0.0915 - accuracy: 0.9705 - val_loss: 0.1120 - val_accuracy: 0.9661\n",
    "\n",
    "Epoch 14/25\n",
    "\n",
    "271/271 [==============================] - 129s 474ms/step - loss: 0.0895 - accuracy: 0.9714 - val_loss: 0.1381 - val_accuracy: 0.9703\n",
    "\n",
    "Epoch 15/25\n",
    "\n",
    "271/271 [==============================] - 128s 473ms/step - loss: 0.0881 - accuracy: 0.9701 - val_loss: 0.1327 - val_accuracy: 0.9672\n",
    "\n",
    "Epoch 16/25\n",
    "\n",
    "271/271 [==============================] - 128s 474ms/step - loss: 0.0873 - accuracy: 0.9718 - val_loss: 0.1111 - val_accuracy: 0.9651\n",
    "\n",
    "Epoch 17/25\n",
    "\n",
    "271/271 [==============================] - 128s 473ms/step - loss: 0.0871 - accuracy: 0.9703 - val_loss: 0.1127 - val_accuracy: 0.9682\n",
    "\n",
    "Epoch 18/25\n",
    "\n",
    "271/271 [==============================] - 128s 474ms/step - loss: 0.0840 - accuracy: 0.9728 - val_loss: 0.1157 - val_accuracy: 0.9688\n",
    "\n",
    "Epoch 19/25\n",
    "\n",
    "271/271 [==============================] - 128s 474ms/step - loss: 0.0831 - accuracy: 0.9716 - val_loss: 0.1107 - val_accuracy: 0.9625\n",
    "\n",
    "Epoch 20/25\n",
    "\n",
    "271/271 [==============================] - 128s 474ms/step - loss: 0.0831 - accuracy: 0.9724 - val_loss: 0.1303 - val_accuracy: 0.9677\n",
    "\n",
    "Epoch 21/25\n",
    "\n",
    "271/271 [==============================] - 128s 474ms/step - loss: 0.0811 - accuracy: 0.9738 - val_loss: 0.1370 - val_accuracy: 0.9672\n",
    "\n",
    "Epoch 22/25\n",
    "\n",
    "271/271 [==============================] - 129s 474ms/step - loss: 0.0866 - accuracy: 0.9714 - val_loss: 0.1221 - val_accuracy: 0.9615\n",
    "\n",
    "Epoch 23/25\n",
    "\n",
    "271/271 [==============================] - 128s 474ms/step - loss: 0.0786 - accuracy: 0.9743 - val_loss: 0.1312 - val_accuracy: 0.9615\n",
    "\n",
    "Epoch 24/25\n",
    "\n",
    "271/271 [==============================] - 128s 473ms/step - loss: 0.0815 - accuracy: 0.9727 - val_loss: 0.1466 - val_accuracy: 0.9682\n",
    "\n",
    "Epoch 25/25\n",
    "\n",
    "271/271 [==============================] - 128s 473ms/step - loss: 0.0792 - accuracy: 0.9729 - val_loss: 0.1127 - val_accuracy: 0.9641"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "t = f.suptitle('Basic CNN Performance', fontsize=12)\n",
    "f.subplots_adjust(top=0.85, wspace=0.3)\n",
    "\n",
    "max_epoch = len(history.history['accuracy'])+1\n",
    "epoch_list = list(range(1,max_epoch))\n",
    "ax1.plot(epoch_list, history.history['accuracy'], label='Train Accuracy')\n",
    "ax1.plot(epoch_list, history.history['val_accuracy'], label='Validation Accuracy')\n",
    "ax1.set_xticks(np.arange(1, max_epoch, 5))\n",
    "ax1.set_ylabel('Accuracy Value')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_title('Accuracy')\n",
    "l1 = ax1.legend(loc=\"best\")\n",
    "\n",
    "ax2.plot(epoch_list, history.history['loss'], label='Train Loss')\n",
    "ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\n",
    "ax2.set_xticks(np.arange(1, max_epoch, 5))\n",
    "ax2.set_ylabel('Loss Value')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_title('Loss')\n",
    "l2 = ax2.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs_scaled = test_data / 255.\n",
    "test_imgs_scaled.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "((8268, 125, 125, 3), (8268,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -l --block-size=MB | grep .h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-rw-r--r-- 1 dipanzan_sarkar dipanzan_sarkar 182MB Mar 13 18:53 basic_cnn.h5\n",
    "    \n",
    "-rw-r--r-- 1 dipanzan_sarkar dipanzan_sarkar 173MB Mar 13 20:43 vgg_finetuned.h5\n",
    "    \n",
    "-rw-r--r-- 1 dipanzan_sarkar dipanzan_sarkar 102MB Mar 13 19:29 vgg_frozen.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_cnn = tf.keras.models.load_model('./basic_cnn.h5')\n",
    "vgg_frz = tf.keras.models.load_model('./vgg_frozen.h5')\n",
    "vgg_ft = tf.keras.models.load_model('./vgg_finetuned.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_cnn_preds = basic_cnn.predict(test_imgs_scaled, batch_size=512)\n",
    "vgg_frz_preds = vgg_frz.predict(test_imgs_scaled, batch_size=512)\n",
    "vgg_ft_preds = vgg_ft.predict(test_imgs_scaled, batch_size=512)\n",
    "\n",
    "basic_cnn_pred_labels = le.inverse_transform([1 if pred > 0.5 else 0 \n",
    "                                                  for pred in basic_cnn_preds.ravel()])\n",
    "vgg_frz_pred_labels = le.inverse_transform([1 if pred > 0.5 else 0 \n",
    "                                                  for pred in vgg_frz_preds.ravel()])\n",
    "vgg_ft_pred_labels = le.inverse_transform([1 if pred > 0.5 else 0 \n",
    "                                                  for pred in vgg_ft_preds.ravel()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_evaluation_utils as meu\n",
    "import pandas as pd\n",
    "\n",
    "basic_cnn_metrics = meu.get_metrics(true_labels=test_labels, predicted_labels=basic_cnn_pred_labels)\n",
    "vgg_frz_metrics = meu.get_metrics(true_labels=test_labels, predicted_labels=vgg_frz_pred_labels)\n",
    "vgg_ft_metrics = meu.get_metrics(true_labels=test_labels, predicted_labels=vgg_ft_pred_labels)\n",
    "\n",
    "pd.DataFrame([basic_cnn_metrics, vgg_frz_metrics, vgg_ft_metrics], \n",
    "             index=['Basic CNN', 'VGG-19 Frozen', 'VGG-19 Fine-tuned'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                           Accuracy  F1 Score: Precision: Recall\n",
    "               Basic CNN    0.9497    0.9497    0.9497    0.9497\n",
    "           VGG-19 Frozen    0.9376    0.9376    0.9379   0.9376 \n",
    "    VGG-19 Fine-tuned       0.9600    0.9600    0.9610   0.9600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "meu.display_model_performance_metrics(true_labels=test_labels, \n",
    "                                      predicted_labels=basic_cnn_pred_labels, \n",
    "                                      classes=list(set(test_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Performance metrics:\n",
    "\n",
    "\n",
    "Model Classification report:\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "     healthy       0.95      0.95      0.95      4075\n",
    "     malaria       0.95      0.95      0.95      4193\n",
    "\n",
    "   micro avg       0.95      0.95      0.95      8268\n",
    "   macro avg       0.95      0.95      0.95      8268\n",
    "weighted avg       0.95      0.95      0.95      8268\n",
    "\n",
    "\n",
    "Prediction Confusion Matrix:\n",
    "\n",
    "                Predicted:        \n",
    "                   healthy malaria\n",
    "Actual: healthy       3884     191\n",
    "        malaria        225    3968"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "meu.display_model_performance_metrics(true_labels=test_labels, \n",
    "                                      predicted_labels=vgg_frz_pred_labels, \n",
    "                                      classes=list(set(test_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Performance metrics:\n",
    "\n",
    "\n",
    "Model Classification report:\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "     healthy       0.93      0.95      0.94      4075\n",
    "     malaria       0.95      0.93      0.94      4193\n",
    "\n",
    "   micro avg       0.94      0.94      0.94      8268\n",
    "   macro avg       0.94      0.94      0.94      8268\n",
    "weighted avg       0.94      0.94      0.94      8268\n",
    "\n",
    "\n",
    "Prediction Confusion Matrix:\n",
    "\n",
    "                Predicted:        \n",
    "                   healthy malaria\n",
    "Actual: healthy       3871     204\n",
    "        malaria        312    3881"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "meu.display_model_performance_metrics(true_labels=test_labels, \n",
    "                                      predicted_labels=vgg_ft_pred_labels, \n",
    "                                      classes=list(set(test_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Performance metrics:\n",
    "\n",
    "\n",
    "Model Classification report:\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "     healthy       0.94      0.98      0.96      4075\n",
    "     malaria       0.98      0.94      0.96      4193\n",
    "\n",
    "   micro avg       0.96      0.96      0.96      8268\n",
    "   macro avg       0.96      0.96      0.96      8268\n",
    "weighted avg       0.96      0.96      0.96      8268\n",
    "\n",
    "\n",
    "Prediction Confusion Matrix:\n",
    "\n",
    "                Predicted:        \n",
    "                   healthy malaria\n",
    "Actual: healthy       4004      71\n",
    "        malaria        260    3933"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
